{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import re\n",
    "from   random import *\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i:  0\n",
      "x:  apple\n",
      "i:  1\n",
      "x:  banana\n",
      "i:  2\n",
      "x:  strawberry\n",
      "i:  0\n",
      "x:  k\n",
      "i:  1\n",
      "x:  a\n",
      "i:  2\n",
      "x:  u\n",
      "i:  3\n",
      "x:  n\n",
      "i:  4\n",
      "x:  g\n",
      "i:  5\n",
      "x:  h\n",
      "i:  6\n",
      "x:  t\n",
      "i:  7\n",
      "x:  e\n",
      "i:  8\n",
      "x:  t\n",
      "i:  9\n",
      "x:  c\n",
      "i:  10\n",
      "x:  h\n",
      "i:  11\n",
      "x:  o\n"
     ]
    }
   ],
   "source": [
    "my_list   = ['apple', 'banana', 'strawberry']\n",
    "my_list_2 = 'kaunghtetcho'\n",
    "\n",
    "for i,x in enumerate(my_list):\n",
    "    print('i: ', i)\n",
    "    print('x: ', x)\n",
    "\n",
    "for i,x in enumerate(my_list_2):\n",
    "    print('i: ', i)\n",
    "    print('x: ', x)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l1 = [\"eat\", \"sleep\", \"repeat\"]\n",
    "s1 = \"geek\"\n",
    " \n",
    "# creating enumerate objects\n",
    "obj1 = enumerate(l1)\n",
    "obj2 = enumerate(s1)\n",
    " \n",
    "print (\"Return type:\", type(obj1))\n",
    "print (list(enumerate(l1)))\n",
    " \n",
    "# changing start index to 2 from 0\n",
    "print (list(enumerate(s1, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "# Load the English language model\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "# Define some raw text\n",
    "raw_text = \"I love natural language processing. It's fascinating!\"\n",
    "\n",
    "# Process the raw text\n",
    "doc = nlp(raw_text)\n",
    "\n",
    "# Iterate over each sentence in the processed document and print it\n",
    "for sent in doc.sents:\n",
    "    print(sent)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "# Load the English language model\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "# Define some raw text\n",
    "raw_text = \"Apple is looking at buying U.K. startup for $1 billion\"\n",
    "\n",
    "# Process the raw text\n",
    "doc = nlp(raw_text)\n",
    "\n",
    "# Collect all named entities into a list\n",
    "sentences = list(doc.ents)\n",
    "\n",
    "print(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dummy values for token_a and token_b\n",
    "token_a = [\"apple\", \"banana\", \"orange\"]  # Contains 3 tokens\n",
    "token_b = [\"cat\", \"dog\"]  # Contains 2 tokens\n",
    "\n",
    "# Constructing segment_id\n",
    "segment_id = [0] * (1 + len(token_a) + 1) + [1] * (len(token_b) + 1)\n",
    "\n",
    "# Printing segment_id\n",
    "print(segment_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 4, 6, 7]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ids = [101, 2054, 2003, 103, 2012, 102, 2054, 2003, 102]\n",
    "word2id = {'[CLS]': 101, '[SEP]': 102, 'apple': 2054, 'banana': 2003}\n",
    "\n",
    "# (0, 101), (1, 2054), (2, 2003), (3, 103), (4, 2012), (5, 102), (6, 2054), (7, 2003), (8, 102)\n",
    "\n",
    "candidates_masked_pos = [i for i, token in enumerate(input_ids) if token != word2id['[CLS]'] and token != word2id['[SEP]']]\n",
    "\n",
    "candidates_masked_pos # 1,2,3,4,6,7 are not special tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_mask =  15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate 15% of the total number of tokens\n",
    "percentage = len(input_ids) * 0.15\n",
    "\n",
    "# Round the percentage to the nearest integer\n",
    "rounded_percentage = round(percentage)\n",
    "\n",
    "# Ensure the rounded percentage is at least 1\n",
    "if rounded_percentage < 1:\n",
    "    n_pred = 1\n",
    "else:\n",
    "    n_pred = rounded_percentage\n",
    "\n",
    "# Ensure n_pred does not exceed max_mask\n",
    "if n_pred > max_mask:\n",
    "    n_pred = max_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7, 4, 3, 6, 1, 2]\n"
     ]
    }
   ],
   "source": [
    "shuffle(candidates_masked_pos)  # Shuffling the list in place\n",
    "\n",
    "print(candidates_masked_pos)  # Printing the shuffled list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "6\n",
      "7\n"
     ]
    }
   ],
   "source": [
    "for i,token in enumerate(input_ids):\n",
    "    if token!= word2id['[CLS]'] and token != word2id['[SEP]']:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "101\n",
      "1\n",
      "2054\n",
      "2\n",
      "2003\n",
      "3\n",
      "103\n",
      "4\n",
      "2012\n",
      "5\n",
      "102\n",
      "6\n",
      "2054\n",
      "7\n",
      "2003\n",
      "8\n",
      "102\n"
     ]
    }
   ],
   "source": [
    "for i,token in enumerate(input_ids):\n",
    "    print(i)\n",
    "    print(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[7, 4, 3, 6, 1, 2]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "candidates_masked_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7]\n",
      "[2003]\n"
     ]
    }
   ],
   "source": [
    "masked_tokens, masked_pos = [], []\n",
    "\n",
    "for pos in candidates_masked_pos[:n_pred]:\n",
    "\n",
    "    masked_pos.append(pos)\n",
    "    masked_tokens.append(input_ids[pos])\n",
    "\n",
    "    print(masked_pos)\n",
    "    print(masked_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "991\n"
     ]
    }
   ],
   "source": [
    "max_len = 1000\n",
    "n_pad = max_len - len(input_ids)\n",
    "# input_ids.extend([0] * n_pad)\n",
    "# segment_id.extend([0] * n_pad)\n",
    "\n",
    "print(n_pad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[101, 2054, 2003, 103, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "# Example input_ids list\n",
    "input_ids = [101, 2054, 2003, 103]\n",
    "\n",
    "# Example value of n_pad (number of zeros to add)\n",
    "n_pad = 3\n",
    "\n",
    "# Extending input_ids with n_pad zeros\n",
    "input_ids.extend([0]*n_pad)\n",
    "\n",
    "# Printing the updated input_ids list\n",
    "print(input_ids)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated masked_tokens: [101, 2054, 2003, 103, 0, 0, 0, 0]\n",
      "Updated masked_pos: [0, 1, 2, 3, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "# Example data\n",
    "max_mask = 10\n",
    "n_pred   = 6\n",
    "masked_tokens = [101, 2054, 2003, 103]\n",
    "masked_pos    = [0, 1, 2, 3]\n",
    "\n",
    "# Check if padding is needed\n",
    "if max_mask > n_pred:\n",
    "    n_pad = max_mask - n_pred\n",
    "    masked_tokens.extend([0] * n_pad)\n",
    "    masked_pos.extend([0] * n_pad)\n",
    "\n",
    "# Print the updated masked_tokens and masked_pos\n",
    "print(\"Updated masked_tokens:\", masked_tokens)\n",
    "print(\"Updated masked_pos:\", masked_pos)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids.extend([0] * n_pad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'segment_id' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mlen\u001b[39m(\u001b[43msegment_id\u001b[49m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'segment_id' is not defined"
     ]
    }
   ],
   "source": [
    "len(segment_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Input IDs: [101, 103, 2003, 103, 103, 102, 2054, 2003, 102]\n",
      "Masked Positions: [3, 4, 1]\n",
      "Masked Tokens: [103, 2012, 2054]\n"
     ]
    }
   ],
   "source": [
    "input_ids  = [101, 2054, 2003, 103, 2012, 102, 2054, 2003, 102]\n",
    "word2id    = {'[CLS]': 101, '[SEP]': 102, 'apple': 2054, 'banana': 2003, '[MASK]': 103}\n",
    "id2word    = {2054: 'apple', 2003: 'banana'}\n",
    "vocab_size = 5000\n",
    "n_pred = 3  # Example number of predictions\n",
    "\n",
    "from random import shuffle, random, randint\n",
    "\n",
    "# Code for generating masked tokens\n",
    "cand_maked_pos = [i for i, token in enumerate(input_ids) if token != word2id['[CLS]'] and token != word2id['[SEP]']]\n",
    "shuffle(cand_maked_pos)\n",
    "masked_tokens, masked_pos = [], []\n",
    "\n",
    "for pos in cand_maked_pos[:n_pred]:\n",
    "    masked_pos.append(pos)  # Remember the position\n",
    "    masked_tokens.append(input_ids[pos])  # Remember the tokens\n",
    "    \n",
    "    rand_num = random()\n",
    "    if rand_num < 0.1:  # 10%\n",
    "        index = randint(0, vocab_size - 1)  # Random index in vocabulary\n",
    "        input_ids[pos] = word2id[id2word[index]]  # Replace with random token\n",
    "    elif rand_num < 0.9:  # 80%\n",
    "        input_ids[pos] = word2id['[MASK]']  # Make mask\n",
    "    else:  # 10% (do nothing)\n",
    "        pass\n",
    "\n",
    "print(\"Original Input IDs:\", input_ids)\n",
    "print(\"Masked Positions:\", masked_pos)\n",
    "print(\"Masked Tokens:\", masked_tokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Java', 14), ('Python', 3), ('JavaScript', 6)]\n",
      "<class 'zip'>\n"
     ]
    }
   ],
   "source": [
    "languages = ['Java', 'Python', 'JavaScript']\n",
    "versions = [14, 3, 6]\n",
    "\n",
    "result = zip(languages, versions)\n",
    "print(list(result))\n",
    "print(type(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('x', 3), ('y', 4), ('z', 5)]\n",
      "c:  ('x', 'y', 'z')\n",
      "<class 'tuple'>\n",
      "v:  (3, 4, 5)\n"
     ]
    }
   ],
   "source": [
    "coordinate = ['x', 'y', 'z']\n",
    "value = [3, 4, 5]\n",
    "\n",
    "result = zip(coordinate, value)\n",
    "result_list = list(result)\n",
    "print(result_list)\n",
    "\n",
    "c, v =  zip(*result_list)\n",
    "print('c: ', c), print(type(c))\n",
    "print('v: ', v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# Define the Embedding class\n",
    "class Embedding(nn.Module):\n",
    "    def __init__(self, vocab_size, max_len, n_segments, d_model):\n",
    "        super(Embedding, self).__init__()\n",
    "        self.tok_embd = nn.Embedding(vocab_size, d_model)\n",
    "        self.pos_embd = nn.Embedding(max_len, d_model)\n",
    "        self.seg_embd = nn.Embedding(n_segments, d_model)\n",
    "        self.norm     = nn.LayerNorm(d_model)\n",
    "        \n",
    "    def forward(self, x, seg):\n",
    "        # x, seg: (bs, len)\n",
    "        seq_len = x.size(1)\n",
    "        pos = torch.arange(seq_len, dtype=torch.long)\n",
    "        pos = pos.unsqueeze(0).expand_as(x)  # (len,) -> (bs, len)\n",
    "        embedding = self.tok_embd(x) + self.pos_embd(pos) + self.seg_embd(seg)\n",
    "        return self.norm(embedding)\n",
    "\n",
    "# Example data\n",
    "vocab_size = 10000  # Vocabulary size\n",
    "max_len = 20        # Maximum sequence length\n",
    "n_segments = 2      # Number of segments (e.g., sentences)\n",
    "d_model = 768       # Embedding size\n",
    "\n",
    "# Instantiate the Embedding model\n",
    "embedding_model = Embedding(vocab_size, max_len, n_segments, d_model)\n",
    "\n",
    "# Example input data\n",
    "input_ids = torch.tensor([[101, 2054, 2003, 102, 0], [201, 202, 102, 0, 0]])  # Batch of input token IDs\n",
    "segment_ids = torch.tensor([[0, 0, 0, 0, 0], [0, 0, 1, 1, 1]])  # Batch of segment IDs\n",
    "\n",
    "# Forward pass through the Embedding model\n",
    "embeddings = embedding_model(input_ids, segment_ids)\n",
    "\n",
    "# Print the shape of the output embeddings\n",
    "print(\"Output embeddings shape:\", embeddings.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Example sequence lengths\n",
    "batch_size = 2\n",
    "len_q = 4  # Length of query sequence\n",
    "len_k = 5  # Length of key sequence\n",
    "\n",
    "# Example query sequence (with padding)\n",
    "seq_q = torch.tensor([\n",
    "    [101, 2054, 2003, 0],  # Padded with 0\n",
    "    [201, 202, 102, 0]     # Padded with 0\n",
    "])\n",
    "\n",
    "# Example key sequence (with padding)\n",
    "seq_k = torch.tensor([\n",
    "    [101, 2054, 2003, 102, 0],  # Padded with 0\n",
    "    [201, 202, 102, 0, 0]        # Padded with 0\n",
    "])\n",
    "\n",
    "# Call the get_attn_pad_mask function\n",
    "pad_attn_mask = get_attn_pad_mask(seq_q, seq_k)\n",
    "\n",
    "# Print the resulting attention mask\n",
    "print(\"Attention Mask:\")\n",
    "print(pad_attn_mask)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# Define the Embedding class\n",
    "class Embedding(nn.Module):\n",
    "    def __init__(self, vocab_size, max_len, n_segments, d_model):\n",
    "        super(Embedding, self).__init__()\n",
    "        self.tok_embed = nn.Embedding(vocab_size, d_model)\n",
    "        self.pos_embed = nn.Embedding(max_len, d_model)\n",
    "        self.seg_embed = nn.Embedding(n_segments, d_model)\n",
    "        self.norm = nn.LayerNorm(d_model)\n",
    "        \n",
    "    def forward(self, x, seg):\n",
    "        # x, seg: (bs, len)\n",
    "        seq_len = x.size(1)\n",
    "        print('seq_len: ', seq_len)\n",
    "        pos = torch.arange(seq_len, dtype=torch.long)  # Create tensor containing indices from 0 to seq_len-1\n",
    "        print('pos: ', pos)\n",
    "        pos = pos.unsqueeze(0).expand_as(x)  # Expand pos to match the shape of x\n",
    "        print('pos after unsqueeze: ', pos)\n",
    "        embedding = self.tok_embed(x) + self.pos_embed(pos) + self.seg_embed(seg)\n",
    "        print('embedding: ', embedding.shape)\n",
    "        return self.norm(embedding)\n",
    "\n",
    "# Example data\n",
    "vocab_size = 10000  # Vocabulary size\n",
    "max_len = 10        # Maximum sequence length\n",
    "n_segments = 2      # Number of segments\n",
    "d_model = 768       # Embedding size\n",
    "\n",
    "# Instantiate the Embedding model\n",
    "embedding_model = Embedding(vocab_size, max_len, n_segments, d_model)\n",
    "\n",
    "# Example input data\n",
    "# Batch size is 2, sequence length is 5\n",
    "x = torch.tensor([[1, 2, 3, 0, 0], [4, 5, 6, 7, 0]])  # Input token IDs\n",
    "seg = torch.tensor([[0, 0, 1, 1, 1], [0, 0, 0, 1, 1]])  # Segment IDs\n",
    "\n",
    "# Forward pass through the Embedding model\n",
    "output = embedding_model(x, seg)\n",
    "\n",
    "# Print the output shape\n",
    "print(\"Output shape:\", output.shape)\n",
    "\n",
    "print('x.size(0): ',x.size(0))\n",
    "print('x.size(1): ',x.size(1))\n",
    "# size() method returns a tuple representing the size of each dimension of the tensor.\n",
    "# batch_size, dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "# numpy.size() method \n",
    " \n",
    "# importing numpy \n",
    "import numpy as np\n",
    " \n",
    "# Making a random array \n",
    "arr = np.array([[1, 2, 3, 4], [5, 6, 7, 8]])\n",
    " \n",
    "# By default, give the total number of elements.\n",
    "print(np.size(arr, 0))\n",
    "print(np.size(arr, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_len = x.size(1)\n",
    "seq_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 2, 3, 4])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos = torch.arange(seq_len, dtype=torch.long)\n",
    "pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos = pos.unsqueeze(0)\n",
    "pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos.expand_as(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 5])\n",
      "torch.Size([1, 1, 5])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "pos = torch.tensor([[0, 1, 2, 3, 4]])  # Shape: (1, 5)\n",
    "x = torch.tensor([[1, 2, 3, 0, 0], [4, 5, 6, 7, 0]])  # Shape: (2, 5)\n",
    "print(pos.shape)\n",
    "pos = pos.unsqueeze(0)\n",
    "print(pos.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "expand(torch.LongTensor{[1, 1, 5]}, size=[2, 5]): the number of sizes provided (2) must be greater or equal to the number of dimensions in the tensor (3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m pos \u001b[38;5;241m=\u001b[39m \u001b[43mpos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexpand_as\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(pos\u001b[38;5;241m.\u001b[39mshape)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: expand(torch.LongTensor{[1, 1, 5]}, size=[2, 5]): the number of sizes provided (2) must be greater or equal to the number of dimensions in the tensor (3)"
     ]
    }
   ],
   "source": [
    "pos = pos.expand_as(x)\n",
    "print(pos.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[False, False, False, False,  True],\n",
      "        [False, False, False, False, False]])\n",
      "tensor([[[False, False, False, False,  True]],\n",
      "\n",
      "        [[False, False, False, False, False]]])\n",
      "Attention Pad Mask:\n",
      "tensor([[[False, False, False, False,  True],\n",
      "         [False, False, False, False,  True],\n",
      "         [False, False, False, False,  True],\n",
      "         [False, False, False, False,  True],\n",
      "         [False, False, False, False,  True]],\n",
      "\n",
      "        [[False, False, False, False, False],\n",
      "         [False, False, False, False, False],\n",
      "         [False, False, False, False, False],\n",
      "         [False, False, False, False, False],\n",
      "         [False, False, False, False, False]]])\n",
      "torch.Size([2, 5, 5])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([2, 5])\n",
      "tensor([[False, False, False,  True,  True],\n",
      "        [False, False, False, False,  True]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "def get_attn_pad_mask(seq_q, seq_k):\n",
    "    batch_size, len_q = seq_q.size()\n",
    "    batch_size, len_k = seq_k.size()\n",
    "    \n",
    "    # eq(zero) is PAD token\n",
    "    pad_attn_mask = seq_k.data.eq(0)  # batch_size x 1 x len_k(=len_q), one is masking\n",
    "    print(pad_attn_mask)\n",
    "    pad_attn_mask = pad_attn_mask.unsqueeze(1)\n",
    "    print(pad_attn_mask)\n",
    "    return pad_attn_mask.expand(batch_size, len_q, len_k)  # batch_size x len_q x len_k\n",
    "\n",
    "# Example data\n",
    "seq_q = torch.tensor([[1, 2, 3, 0, 0], [4, 5, 6, 7, 0]])  # Query sequences\n",
    "seq_k = torch.tensor([[1, 2, 3, 4, 0], [5, 6, 7, 8, 9]])  # Key sequences\n",
    "\n",
    "# Call the function\n",
    "\n",
    "mask = get_attn_pad_mask(seq_q, seq_k)\n",
    "\n",
    "# Print the result\n",
    "print(\"Attention Pad Mask:\")\n",
    "print(mask)\n",
    "\n",
    "print(mask.shape)\n",
    "print(type(seq_q))\n",
    "print(seq_q.size())\n",
    "print(seq_q.data.eq(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 5])\n",
      "torch.Size([2, 1, 5])\n"
     ]
    }
   ],
   "source": [
    "seq_k = torch.tensor([[1, 2, 3, 4, 0], [5, 6, 7, 8, 9]])\n",
    "pad_attn_mask = seq_k.data.eq(0)\n",
    "print(pad_attn_mask.shape)\n",
    "pad_attn_mask = pad_attn_mask.unsqueeze(1)\n",
    "print(pad_attn_mask.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'len_q' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[30], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m pad_attn_mask\u001b[38;5;241m.\u001b[39mexpand(batch_size, \u001b[43mlen_q\u001b[49m, len_k)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'len_q' is not defined"
     ]
    }
   ],
   "source": [
    "pad_attn_mask.expand(batch_size, len_q, len_k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q = torch.tensor([[1, 2, 3],\n",
    "                  [4, 5, 6]])\n",
    "\n",
    "K = torch.tensor([[7, 8],\n",
    "                  [9, 10],\n",
    "                  [11, 12]])\n",
    "\n",
    "V = torch.tensor([[0.1, 0.2],\n",
    "                  [0.3, 0.4],\n",
    "                  [0.5, 0.6]])\n",
    "\n",
    "attn_mask = torch.tensor([[False, True],\n",
    "                          [False, False]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K.size(-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 4],\n",
       "        [2, 5],\n",
       "        [3, 6]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Q.transpose(-1,-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 5.0000e-01,  8.0000e-01, -1.0000e+09],\n",
       "        [ 2.0000e-01, -1.0000e+09, -1.0000e+09]])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Example attention scores tensor\n",
    "scores = torch.tensor([[0.5, 0.8, 0.6],\n",
    "                       [0.2, 0.4, 0.9]])\n",
    "\n",
    "# Example attention mask tensor\n",
    "attn_mask = torch.tensor([[False, False, True],\n",
    "                          [False, True, True]])\n",
    "\n",
    "\n",
    "# Mask out attention scores based on the mask\n",
    "scores.masked_fill_(attn_mask, -1e9)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Softmax Scores:\n",
      "tensor([[0.3949, 0.5330, 0.0721],\n",
      "        [0.2807, 0.1540, 0.5653]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Example attention scores tensor\n",
    "scores = torch.tensor([[0.5, 0.8, -1.2],\n",
    "                       [0.2, -0.4, 0.9]])\n",
    "\n",
    "# Apply softmax along the last dimension\n",
    "softmax_scores = torch.nn.Softmax(dim=-1)(scores)\n",
    "\n",
    "print(\"Softmax Scores:\")\n",
    "print(softmax_scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Query (Q) vectors: torch.Size([5, 64])\n",
      "Shape of Key (K) vectors: torch.Size([5, 64])\n",
      "Shape of Value (V) vectors: torch.Size([5, 64])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Dummy input sequence with 5 tokens and 768-dimensional embeddings\n",
    "input_sequence = torch.randn(5, 768)\n",
    "\n",
    "# Projection matrices for query, key, and value\n",
    "W_q = torch.randn(768, 64)  # Projection matrix for query\n",
    "W_k = torch.randn(768, 64)  # Projection matrix for key\n",
    "W_v = torch.randn(768, 64)  # Projection matrix for value\n",
    "\n",
    "# Projecting input sequence into query, key, and value vectors\n",
    "Q = input_sequence @ W_q  # Query vectors of shape (5, 64)\n",
    "K = input_sequence @ W_k  # Key vectors of shape (5, 64)\n",
    "V = input_sequence @ W_v  # Value vectors of shape (5, 64)\n",
    "\n",
    "print(\"Shape of Query (Q) vectors:\", Q.shape)\n",
    "print(\"Shape of Key (K) vectors:\", K.shape)\n",
    "print(\"Shape of Value (V) vectors:\", V.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 768])\n",
      "q:  Linear(in_features=768, out_features=512, bias=True)\n",
      "k:  Linear(in_features=768, out_features=512, bias=True)\n",
      "v:  Linear(in_features=768, out_features=512, bias=True)\n"
     ]
    }
   ],
   "source": [
    "d_model = 768\n",
    "d_ff = d_model * 4\n",
    "d_k = d_v = 64\n",
    "\n",
    "# Example code to create tensors with specified dimensions\n",
    "import torch\n",
    "\n",
    "# Position-wise FFN\n",
    "pos_ffn_input = torch.randn(10, d_model)  # Example input tensor with shape [batch_size, d_model]\n",
    "print(pos_ffn_input.shape)\n",
    "linear_layer1 = torch.nn.Linear(d_model, d_ff)  # Linear projection to hidden layer size (d_ff)\n",
    "linear_layer2 = torch.nn.Linear(d_ff, d_model)  # Linear projection back to d_model size\n",
    "\n",
    "# Multi-head attention\n",
    "n_heads = 8\n",
    "seq_len = 10\n",
    "input_sequence = torch.randn(10, seq_len, d_model)  # Example input tensor with shape [batch_size, seq_len, d_model]\n",
    "linear_q = torch.nn.Linear(d_model, n_heads * d_k)  # Linear projection for queries\n",
    "linear_k = torch.nn.Linear(d_model, n_heads * d_k)  # Linear projection for keys\n",
    "linear_v = torch.nn.Linear(d_model, n_heads * d_v)  # Linear projection for values\n",
    "\n",
    "print('q: ', linear_q)\n",
    "print('k: ', linear_k)\n",
    "print('v: ', linear_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
